import math, random, sys
from optparse import OptionParser
usage = '%prog [options] <feat-dim> <num-leaves> <num-hidden-layers> <num-hidden-neurons>  >nnet-proto-file'
parser = OptionParser(usage)
parser.add_option('--no-softmax', dest='with_softmax', help='Do not put <SoftMax> in the prototype [default: %default]', default=True, action='store_false')
parser.add_option('--activation-type', dest='activation_type', help='Select type of activation function : (<Sigmoid>|<Tanh>) [default: %default]', default='<Sigmoid>', type='string')
parser.add_option('--hid-bias-mean', dest='hid_bias_mean', help='Set bias for hidden activations [default: %default]', default=(-2.0), type='float')
parser.add_option('--hid-bias-range', dest='hid_bias_range', help='Set bias range for hidden activations (+/- 1/2 range around mean) [default: %default]', default=4.0, type='float')
parser.add_option('--param-stddev-factor', dest='param_stddev_factor', help='Factor to rescale Normal distriburtion for initalizing weight matrices [default: %default]', default=0.1, type='float')
parser.add_option('--bottleneck-dim', dest='bottleneck_dim', help='Make bottleneck network with desired bn-dim (0 = no bottleneck) [default: %default]', default=0, type='int')
parser.add_option('--no-glorot-scaled-stddev', dest='with_glorot', help='Generate normalized weights according to X.Glorot paper, but mapping U->N with same variance (factor sqrt(x/(dim_in+dim_out)))', action='store_false', default=True)
parser.add_option('--no-smaller-input-weights', dest='smaller_input_weights', help='Disable 1/12 reduction of stddef in input layer [default: %default]', action='store_false', default=True)
parser.add_option('--max-norm', dest='max_norm', help='Max radius of neuron-weights in L2 space (if longer weights get shrinked, not applied to last layer, 0.0 = disable) [default: %default]', default=0.0, type='float')
(o, args) = parser.parse_args()
if (len(args) != 4):
    parser.print_help()
    sys.exit(1)
(feat_dim, num_leaves, num_hid_layers, num_hid_neurons) = map(int, args)
assert (feat_dim > 0)
assert (num_leaves > 0)
assert (num_hid_layers >= 0)
assert (num_hid_neurons > 0)
if ((num_hid_layers == 0) and (o.bottleneck_dim != 0)):
    assert (o.bottleneck_dim > 0)
    assert (num_hid_layers == 0)
    print '<NnetProto>'
    print ('<LinearTransform> <InputDim> %d <OutputDim> %d <ParamStddev> %f <LearnRateCoef> %f' % (feat_dim, o.bottleneck_dim, ((o.param_stddev_factor * Glorot(feat_dim, o.bottleneck_dim)) * 0.75), 0.1))
    print ('<AffineTransform> <InputDim> %d <OutputDim> %d <BiasMean> %f <BiasRange> %f <ParamStddev> %f <LearnRateCoef> %f <BiasLearnRateCoef> %f <MaxNorm> %f' % (o.bottleneck_dim, num_hid_neurons, o.hid_bias_mean, o.hid_bias_range, ((o.param_stddev_factor * Glorot(o.bottleneck_dim, num_hid_neurons)) * 0.75), 0.1, 0.1, o.max_norm))
    print ('%s <InputDim> %d <OutputDim> %d' % (o.activation_type, num_hid_neurons, num_hid_neurons))
    print ('<AffineTransform> <InputDim> %d <OutputDim> %d <BiasMean> %f <BiasRange> %f <ParamStddev> %f <LearnRateCoef> %f <BiasLearnRateCoef> %f' % (num_hid_neurons, num_leaves, 0.0, 0.0, (o.param_stddev_factor * Glorot(num_hid_neurons, num_leaves)), 1.0, 0.1))
    if o.with_softmax:
        print ('<Softmax> <InputDim> %d <OutputDim> %d' % (num_leaves, num_leaves))
    print '</NnetProto>'
    sys.exit(0)
if (num_hid_layers == 0):
    print '<NnetProto>'
    print ('<AffineTransform> <InputDim> %d <OutputDim> %d <BiasMean> %f <BiasRange> %f <ParamStddev> %f' % (feat_dim, num_leaves, 0.0, 0.0, (o.param_stddev_factor * Glorot(feat_dim, num_leaves))))
    if o.with_softmax:
        print ('<Softmax> <InputDim> %d <OutputDim> %d' % (num_leaves, num_leaves))
    print '</NnetProto>'
    sys.exit(0)
assert (num_hid_layers > 0)
print '<NnetProto>'
print ('<AffineTransform> <InputDim> %d <OutputDim> %d <BiasMean> %f <BiasRange> %f <ParamStddev> %f <MaxNorm> %f' % (feat_dim, num_hid_neurons, o.hid_bias_mean, o.hid_bias_range, ((o.param_stddev_factor * Glorot(feat_dim, num_hid_neurons)) * (math.sqrt((1.0 / 12.0)) if o.smaller_input_weights else 1.0)), o.max_norm))
print ('%s <InputDim> %d <OutputDim> %d' % (o.activation_type, num_hid_neurons, num_hid_neurons))
for i in range((num_hid_layers - 1)):
    print ('<AffineTransform> <InputDim> %d <OutputDim> %d <BiasMean> %f <BiasRange> %f <ParamStddev> %f <MaxNorm> %f' % (num_hid_neurons, num_hid_neurons, o.hid_bias_mean, o.hid_bias_range, (o.param_stddev_factor * Glorot(num_hid_neurons, num_hid_neurons)), o.max_norm))
    print ('%s <InputDim> %d <OutputDim> %d' % (o.activation_type, num_hid_neurons, num_hid_neurons))
if (o.bottleneck_dim != 0):
    assert (o.bottleneck_dim > 0)
    print ('<LinearTransform> <InputDim> %d <OutputDim> %d <ParamStddev> %f <LearnRateCoef> %f' % (num_hid_neurons, o.bottleneck_dim, ((o.param_stddev_factor * Glorot(num_hid_neurons, o.bottleneck_dim)) * 0.75), 0.1))
    print ('<AffineTransform> <InputDim> %d <OutputDim> %d <BiasMean> %f <BiasRange> %f <ParamStddev> %f <LearnRateCoef> %f <BiasLearnRateCoef> %f <MaxNorm> %f' % (o.bottleneck_dim, num_hid_neurons, o.hid_bias_mean, o.hid_bias_range, ((o.param_stddev_factor * Glorot(o.bottleneck_dim, num_hid_neurons)) * 0.75), 0.1, 0.1, o.max_norm))
    print ('%s <InputDim> %d <OutputDim> %d' % (o.activation_type, num_hid_neurons, num_hid_neurons))
print ('<AffineTransform> <InputDim> %d <OutputDim> %d <BiasMean> %f <BiasRange> %f <ParamStddev> %f <LearnRateCoef> %f <BiasLearnRateCoef> %f' % (num_hid_neurons, num_leaves, 0.0, 0.0, (o.param_stddev_factor * Glorot(num_hid_neurons, num_leaves)), 1.0, 0.1))
if o.with_softmax:
    print ('<Softmax> <InputDim> %d <OutputDim> %d' % (num_leaves, num_leaves))
print '</NnetProto>'
sys.exit(0)
