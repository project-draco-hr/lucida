{
  TEST_TARGET_GENERATION=true;
  MsgPrinter.enableStatusMsgs(true);
  MsgPrinter.enableErrorMsgs(true);
  MsgPrinter.printStatusMsg("Creating tokenizer...");
  if (!OpenNLP.createTokenizer("res/nlp/tokenizer/opennlp/EnglishTok.bin.gz"))   MsgPrinter.printErrorMsg("Could not create tokenizer.");
  MsgPrinter.printStatusMsg("Creating stemmer...");
  SnowballStemmer.create();
  MsgPrinter.printStatusMsg("Creating POS tagger...");
  if (!OpenNLP.createPosTagger("res/nlp/postagger/opennlp/tag.bin.gz","res/nlp/postagger/opennlp/tagdict"))   MsgPrinter.printErrorMsg("Could not create POS tagger.");
  MsgPrinter.printStatusMsg("Creating chunker...");
  if (!OpenNLP.createChunker("res/phrasechunker/opennlp/" + "EnglishChunk.bin.gz"))   MsgPrinter.printErrorMsg("Could not create chunker.");
  MsgPrinter.printStatusMsg("Creating Stanford NE tagger...");
  if (!StanfordNeTagger.isInitialized() && !StanfordNeTagger.init())   MsgPrinter.printErrorMsg("Could not create Stanford NE tagger.");
  GoogleTermImportanceFilter gtif=new GoogleTermImportanceFilter(NO_NORMALIZATION,NO_NORMALIZATION,false);
  String[] targets=gtif.getTargets("Warren Moon");
  final HashMap<String,TermCounter> termCounters=gtif.getTermCounters(targets);
  ArrayList<String> termList=new ArrayList<String>(termCounters.keySet());
  Collections.sort(termList,new Comparator<String>(){
    public int compare(    String o1,    String o2){
      int tc1=termCounters.get(o1).getValue();
      int tc2=termCounters.get(o2).getValue();
      return ((tc1 == tc2) ? o1.compareTo(o2) : (tc2 - tc1));
    }
  }
);
  Iterator<String> terms=termList.iterator();
  int atLeast5=0;
  while (terms.hasNext()) {
    String term=terms.next();
    int tc=termCounters.get(term).getValue();
    System.out.println(term + ": " + tc);
    if (tc > 4)     atLeast5++;
  }
  System.out.println("At least 5 times: " + atLeast5);
}
